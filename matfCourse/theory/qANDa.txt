Vim folding brush-up:
:set foldmethod=indent   // sakrij sve odgovore
:set foldmethod=syntax   // prikaži sve odgovore

za = toogle fold
zo = fold open
zc = fold close


===========================================================================
# 1 Uvod:
===========================================================================

1.1 Šta je mašinsko učenje, opisati svojim rečima?
    -
    -

1.2 Koje su osnovne grupe problema mašinskog učenja?
    -
    -

1.3 Opisati nadgledano učenje?
    -
    -

1.4 Opisati nenadgledano učenje?
    -
    -

1.5 Opisati učenje uslovljavanjem?
    -
    -

===========================================================================
# 2. Nadgledano učenje
===========================================================================

2.0.1 Šta je model?
    -
    - Model je funkcija koja kao ulaz prima vrednosti atributa, a kao izlaz vraća vrednosti ciljne promenljive.

2.0.2 Šta predstavlja generalizacija?
    -
    - Generalizacija predstavlja sposobnost modela da na osnovu proizvoljih vrednosti atributa dobro proceni ciljnu promenljivu.

2.0.3 Koje su osnovne vrste problema nadgledanog učenja?
    -
    - Regresija i klasifikacija.

2.0.4 Šta je regresija?
    -
    - Regresija predstavlja problem nadgledanog učenja sa neprekidnom ciljnom promenljivom.

2.0.5 Šta je klasifikacija?
    -
    - Regresija predstavlja problem nadgledanog učenja sa kategoričkom ciljnom promenljivom.

2.0.6 Šta su kategoričke promenljive?
    -
    - Kategoričke promenljive imaju konačan broj različitih vrednosti koji mogu da uzmu, i ne mogu se urediti.

===========================================================================
## 2.1 Postavka problema nadgledanog učenja
===========================================================================

2.1.1 Čime je dat odnos između atributa i ciljne promenljive?
    -
    - Odnos između atributa i ciljne promenljive dat je zajedničkom raspodelom verovatnoća.

2.1.2 Šta se koristi kao zamena za zajedničku raspodelu verovatnoće atributa i ciljne promenljive?
    -
    - Model f(x), koji vrednostima atributa dodeljuje vrednosti ciljne promenljive.

2.1.3 Šta predstavlja kvalitet modela?
    -
    - Kvalitet modela predstavlja koliko dobro procenjuje vrednosti ciljne promenljive.

2.1.4 Šta je funkcija greške?
    -
    - Funkcija greške predstavlja razliku između ciljne promenljive i procene ciljne promenljive date od strane modela po nekoj metrici.

2.1.5 Šta je funkcional rizika ili stvarni rizik? Navesti formulu u opštem slučaju.
    -
    -
    
2.1.6 Iz kojih razloga je nemoguće direktno rešiti problem nadgledanog učenja u svom teorijskom obliku?
    -
    - Ne znamo zajedniču raspodelu verovatnoća atributa i ciljne promenljive. Skup funkcija po kojem minimizujemu stvarni rizik je beskonačan.

===========================================================================
## 2.2 Princip minimizacije empirijskog rizika
===========================================================================

2.2.1 Skup funkcija po kojem se može minimizovati stvarni rizik pri nadgledanom učenju je beskonačan, kako se ovaj problem rešava?
    -
    - Uzimamo konačan skup koji predstavljamo reprezentacijom modela, po kojem minimizujemo rizik.

2.2.2 Šta predstavlja reprezentacija modela? Navesti neki primer.
    -
    - Reprezentacija modela predstavlja skup različitih modela koji mogu biti izraženi.

2.2.3 Kako se rešava problem nedostupnosti gustine raspodele p(x,y) kod nadgledanog učenja?
    -
    - Gustinu raspodele aproksimiramo na osnovu uzorka.

2.2.4 Koja je razlika između stvarnog rizika i empirijskog rizika?
    -
    - Empirijski rizik predstavlja procenu stvarnog rizika.

2.2.5 Da li funkcija koja minimizuje emprijiski rizik u svakom slučaju dobro aproksimira funkciju koja minimizuje stvarni rizik? Obrazložiti odgovor.
    -
    - Ne, funkcija f se može se ponašati super na tačkama na kojima uči, ali pritom loše generalizovati. Ova pojava se naziva preprilagođavanje.
    - primer - karakteristična funkcija, svuda 0, osim u tačkama uzorka, gde je baš vrednost ciljne promenljive.

2.2.6 Kako glasi regresiona funkcija?
    -
    - r(x) = E(y|x) = Integral( y*p(y|x) dy )

2.2.7 Navesti funkciju greške kod regresije koja se najčešće koristi.
    -
    - L(u,v) = (u-v)^2   
    - kvadratna greška

2.2.8 Kako glasi formulacija principa minimizacije empirijskog rizika za regresiju?
    -
    - funkcija koja minimizuje empirijski rizik se uzima za aproksimaciju funkcije koja minimizuje stvarni rizik.

2.2.9 Da li funkcija greške mora biti simetrična? Obrazložiti.
    -
    - Ne mora, ako želimo na različit način da kaznimo različite vrste grešaka.

2.2.10 Navesti funkciju greške kod klasifikacije.
    -
    - L(u|v) = I(u=/=v)
    
===========================================================================
2.3 Preprilagođavanje
===========================================================================

2.3.1 Objasniti pojam preprilagođavanja.
    -
    -

2.3.2 Da li je minimizacija srednje greške jedini i najbolji kriterijum za procenu kvaliteta modela? Obrazložiti odgovor.
    -
    -

2.3.3 Koji sve mogu biti razlozi preprilagođavanja?
    -
    -
    
2.3.4 Kako se rešava problem preprilagođavanja?
    -
    -

===========================================================================
2.4 Regularizacija
===========================================================================

2.4.1 Šta predstavlja regularizacija?
    -
    - Preprilagođavanje predstavlja bilo kakav vid smanjivanja fleksibilnosti modela, u pokušaju da se smanji preprilagođavanje a poveća mogućnost generalizovanja modela.

2.4.2 Čemu služi regularizacioni parametar lambda?
    -
    - Služi da pridodamo važnost regularizacionom izrazu u odnosu na minimizaciju srednje greške.

2.4.3 Navedite primer regularizacionog izraza.
    -
    - Lnorme, menhetn, euklidsko

2.4.4 Kako se utiče na model regularizacioni parametar u svojim ekstremnim vrednostima.
    - kad je 0, uopšte ne utiče, tako da ako je model dovoljno fleksibilan može doći do preprilagođavanja.
    - ako teži beskonačnosti, samo on i utiče na minimizaciju, tako da model u potpunosti gubi moć prilagođavanja, jedino mu je bitno da svi parametri imaju vrednosti 0.

2.4.5 Da li regularizacija može loše uticati na naš model? Obrazložiti.
    -
    - Dap, ako previše regularizujemo model u potpunosti gubi mogućnost prilagođavanja.


===========================================================================
2.5 Nagodba između sistematskog odstupanja i varijanse
===========================================================================

===========================================================================
2.6 Teorijske garancije kvaliteta garanije
===========================================================================

2.6.1 Čime se bavi statistička teorija učenja
    -
	- STU se bavi proučavanjem moći generalizacije različitih skupova modela.

2.6.2 Koja su osnovna pitanja koja se postavljaju u statičkoj teoriji učenja?
    -
	- Koliki može biti stvarni rizik modela, ako znamo njegov empirijski rizik.
	- Koliko je stvarni rizik modela f viši od stvarnog rizika najboljeg modela iz nekog skupa modela.
	- Koliko je stvarni rizik modela f viši od stvarnog rizika najboljeg mogućeg modela.
	
2.6.3 Od čega sve zavisi gornja granica stvarnog rizika u odnosu na neki model f?
    -
	- Od empirijskog rizika modela f, veličine skupa podataka i skupa modela iz kojeg se bira f.

2.6.4 Šta nam govori hefdingova nejednakost?
    -
	- Hefdingova nejednakost nam kvantifikuje brzinu konvergencije empirijskog rizika nekog modela ka njegovom stvarnom riziku.

2.6.5 Šta predstavlja funkcija rasta?
    -
	- Funkcija rasta je maksimalan broj načina da funkcije iz skupa F klasifikuju N tačaka.


2.6.6 Šta predstavlja Vapnik-Červonenkisova dimenzija skupa funkcija F?
    -
	- VC dimenzija skupa funkcija F je najveći broj N, za koji postoji skup tačaka veličine N koje se mogu klasifikovati pomoću skupa funkcija F na sve moguće načine.

2.6.7 Koja je VC dimenzija skupa svih pravih u prostoru?
    -
	- 2, ako se tačka nalazi na pravoj onda pripada jednoj klasi, drugoj u suprotnom.
	
2.6.8 Dati primer skupa funkcija koji ima beskonačnu VC dimenziju.
    -
	- {sgn(sin(wx)) | w in R}
	- SVM sa gausovim kernelom

2.6.9 Kakav treba da bude skup modela, da bi dovoljno velik broj podataka garantovao poverenje u empirijsku ocenu stvarnog rizika?
    -
	- Skup modela treba biti konačne VC dimenzije.

===========================================================================
2.7 Veza statističke teorije učenja sa filozofijom nauke
===========================================================================

2.7.1 Koje je najbolje objašnjenje neke pojave u smislu Okamove oštrice?
    -
	- Ono koje pored objašnjenja te pojave, objašnjava što manje.

===========================================================================
2.8 Vrste modela
===========================================================================

2.8.1 Koje vrste modela postoje, prema tome koliku količinu informacije pokušavaju da modeluju?
    -
	- Probabilistički generativni
	- Probabilistički diskriminativni
	- Neprobabilistički diskriminativni

2.8.2 Šta pokušavaju da modeluju probabilistički generativni modeli?
    -
    -

2.8.3 Šta pokušavaju da modeluju probabilistički diskriminativni modeli?
    -
    -

2.8.4 Šta pokušavaju da modeluju neprobabilistički diskriminativni modeli?
    -
    -


